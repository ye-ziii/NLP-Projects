{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSEIFshwIrcW"
      },
      "source": [
        "## NLP Topic Modeling Project\n",
        "\n",
        "### Project Summary\n",
        "This project aims to apply appropriate topic modeling techniques to identify top N most important topics respectively from a collection of tweets and a collection of news articles about one particular company.\n",
        "\n",
        "### Data\n",
        "The data has 9,962 news articles and 9,941 tweets.\n",
        "\n",
        "### Project Sections\n",
        "\n",
        "1. Data Import\n",
        "\n",
        "2. Text Data Cleaning\n",
        "\n",
        "3. Topic Modeling\n",
        " - Create Bigrams & Trigrams\n",
        " - Select Right Number of Topics via Coherence Score Analysis\n",
        " - Visualize Actual Topics\n",
        "\n",
        "### Author & Platform\n",
        "Yezi Liu conducted this project independently in Visual Studio Code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bDgxaLu00Pe"
      },
      "source": [
        "## Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghDX74oS-MXh"
      },
      "outputs": [],
      "source": [
        "# Running this cell may make changes to your environment\n",
        "\n",
        "# !pip install pyLDAvis\n",
        "# pip install --upgrade scipy numpy pandas gensim pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17WrmjHRIrcX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial.distance import jaccard\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.util import ngrams\n",
        "from itertools import combinations\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import numpy as np\n",
        "import itertools\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import gensim\n",
        "from gensim import corpora, models\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.models import Phrases\n",
        "from gensim.corpora import Dictionary\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgCc1FU203pM"
      },
      "source": [
        "## Set Up Environmental Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YZo4uyD09YN"
      },
      "outputs": [],
      "source": [
        "NEWS_DATA_PATH = 'https://storage.googleapis.com/msca-bdp-data-open/news/nlp_a_6_news.json'\n",
        "TWEETS_DATA_PATH = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/nlp_a_6_tweets.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnkGVI91IrcX"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiqs6KFJ1Tau"
      },
      "source": [
        "### News Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JMhH1WYIrcX",
        "outputId": "5c4389ee-9eda-4e02-e5d8-5a380bd077ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample contains 9,962 news articles\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>date</th>\n",
              "      <th>language</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://oaklandnewsnow.com/breaking-bts-announces-las-vegas-us-concert-date-in-2022/</td>\n",
              "      <td>2022-02-24</td>\n",
              "      <td>en</td>\n",
              "      <td>BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, World</td>\n",
              "      <td>BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, WorldSorry, you have Javascript Disabled! To see this page as it is meant to appear, please enable your Javascript!BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, WorldSkip to contentMenuSearch for:SearchOakland News Now – Oakland News, SF Bay Area, East Bay, California, WorldOakland...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.newsdzezimbabwe.co.uk/2022/04/mai-tt-weds.html</td>\n",
              "      <td>2022-04-09</td>\n",
              "      <td>en</td>\n",
              "      <td>MAI TT WEDS newsdzeZimbabweNewsdzeZimbabwe</td>\n",
              "      <td>MAI TT WEDS newsdzeZimbabweNewsdzeZimbabweskip to main  |      skip to sidebarHomeAboutContactAdvertiseNewsdzeZimbabweOur Zimbabwe Our NewsHomeNewsBusinessEntertainmentSaturday, 9 April 2022MAI TT WEDSSaturday, April 09, 2022  NewsdzeZimbabwe   0 Best moments... @Chakariboy @NyamayaroArron @restmutore @Lattynyangu pic.twitter.com/MsrhcFXUJj— H-Metro (@HMetro_) April 9, 2022 Posted in:  Share to TwitterShare to FacebookOlder PostHome0comments:        Post a CommentFollow NewsdzeZimbabweRecent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                   url  \\\n",
              "0  http://oaklandnewsnow.com/breaking-bts-announces-las-vegas-us-concert-date-in-2022/   \n",
              "1                            http://www.newsdzezimbabwe.co.uk/2022/04/mai-tt-weds.html   \n",
              "\n",
              "        date language  \\\n",
              "0 2022-02-24       en   \n",
              "1 2022-04-09       en   \n",
              "\n",
              "                                                                                                                                     title  \\\n",
              "0  BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, World   \n",
              "1                                                                                               MAI TT WEDS newsdzeZimbabweNewsdzeZimbabwe   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
              "0  BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, WorldSorry, you have Javascript Disabled! To see this page as it is meant to appear, please enable your Javascript!BREAKING: BTS Announces LAS VEGAS, US Concert Date in 2022! | Oakland News Now - Oakland News, SF Bay Area, East Bay, California, WorldSkip to contentMenuSearch for:SearchOakland News Now – Oakland News, SF Bay Area, East Bay, California, WorldOakland...  \n",
              "1  MAI TT WEDS newsdzeZimbabweNewsdzeZimbabweskip to main  |      skip to sidebarHomeAboutContactAdvertiseNewsdzeZimbabweOur Zimbabwe Our NewsHomeNewsBusinessEntertainmentSaturday, 9 April 2022MAI TT WEDSSaturday, April 09, 2022  NewsdzeZimbabwe   0 Best moments... @Chakariboy @NyamayaroArron @restmutore @Lattynyangu pic.twitter.com/MsrhcFXUJj— H-Metro (@HMetro_) April 9, 2022 Posted in:  Share to TwitterShare to FacebookOlder PostHome0comments:        Post a CommentFollow NewsdzeZimbabweRecent...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news_df = pd.read_json(NEWS_DATA_PATH, orient='records', lines=True)\n",
        "print(f'Sample contains {news_df.shape[0]:,.0f} news articles')\n",
        "news_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLCR33i9IrcY"
      },
      "source": [
        "### Tweets data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwpYf2wiIrcY",
        "outputId": "6bcca27b-0163-4a1c-cd08-03bca8dbe3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample contains 9,941 tweets\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lang</th>\n",
              "      <th>date</th>\n",
              "      <th>name</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1484553027222741001</td>\n",
              "      <td>en</td>\n",
              "      <td>2022-01-21</td>\n",
              "      <td>Dylan Green</td>\n",
              "      <td>RT</td>\n",
              "      <td>*Microsoft has entered the chat* https://t.co/Uz3pZrk6B3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1505486305102557184</td>\n",
              "      <td>en</td>\n",
              "      <td>2022-03-20</td>\n",
              "      <td>Rahim Rajwani</td>\n",
              "      <td></td>\n",
              "      <td>\"I actually use an @Android phone. Some #Android manufacturers pre-install @Microsoft software in a way that makes it easy for me. They’re more flexible about how the software connects up with the OS. So that’s what I ended up getting used to.\"\\nhttps://t.co/C0VjfS9PUO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id lang       date           name retweeted  \\\n",
              "0  1484553027222741001   en 2022-01-21    Dylan Green        RT   \n",
              "1  1505486305102557184   en 2022-03-20  Rahim Rajwani             \n",
              "\n",
              "                                                                                                                                                                                                                                                                            text  \n",
              "0                                                                                                                                                                                                                       *Microsoft has entered the chat* https://t.co/Uz3pZrk6B3  \n",
              "1  \"I actually use an @Android phone. Some #Android manufacturers pre-install @Microsoft software in a way that makes it easy for me. They’re more flexible about how the software connects up with the OS. So that’s what I ended up getting used to.\"\\nhttps://t.co/C0VjfS9PUO  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df = pd.read_json(TWEETS_DATA_PATH, orient='records', lines=True)\n",
        "print(f'Sample contains {tweets_df.shape[0]:,.0f} tweets')\n",
        "tweets_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koBEztdfIrcY"
      },
      "outputs": [],
      "source": [
        "news_df = news_df[news_df['language']=='en'].reset_index(drop=True)\n",
        "\n",
        "tweets_df = tweets_df[tweets_df['lang']=='en'].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhz-sbLN15GY"
      },
      "source": [
        "## Text Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_YlWfFo2Urh"
      },
      "source": [
        "### News Article Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gNgZAhT2abr"
      },
      "source": [
        "Since in the actual text of news articles, there are many unusually long tokens(several words connected together without a space), such as readsoffersnewfind, they are usually from web-related buttons or ads on a specific web page and are unrelated to the news article contents. So I added a cleaning rule to remove tokens longer than 18 characters(single words are usually not that long)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD4tUcWHIrcY",
        "outputId": "19560fd2-7c71-4275-fef4-896af3dd29c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/lize/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def cleaned_news(text, max_length=18, min_length=3):\n",
        "    \"\"\"\n",
        "    This function cleans the news article text.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'(?:\\@|http?\\://|https?\\://|www)\\S+', '', text)\n",
        "    text = re.sub(r'(?:\\n)', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = nltk.tokenize.word_tokenize(text)\n",
        "    return ' '.join([lemma.lemmatize(token.lower()) for token in tokens\n",
        "        if token.lower() not in stop_words\n",
        "        and token.isalpha()\n",
        "        and not token.isnumeric()\n",
        "        and len(token) <= max_length\n",
        "        and len(token) >= min_length])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ynS47-A2m7N"
      },
      "source": [
        "After careful examination, I found out that almost all titles are already included in the news text. And even if some titles are not included, they should convey the same theme as the text anyway. To effectively use information from both titles and texts without increasing unnecessary computational cost, I decided to just use news article text to represent both sources of information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rup6_YZcIrcY"
      },
      "outputs": [],
      "source": [
        "news_df['cleaned_news_text'] = news_df['text'].apply(lambda x: cleaned_news(x))\n",
        "news_df['cleaned_news_title'] = news_df['title'].apply(lambda x: cleaned_news(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwBGP_6j2zEi"
      },
      "source": [
        "### Tweets Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pySzy9TGIrcY"
      },
      "outputs": [],
      "source": [
        "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=False, reduce_len=True)\n",
        "\n",
        "# Remove urls, \\n, emojis, #, @ for tweets as well as punctuations, stop words, and numbers.\n",
        "def cleaned_tweets(text, min_length=3):\n",
        "    \"\"\"\n",
        "    This function cleans the tweets text.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'(?:\\@|http?\\://|https?\\://|www)\\S+', '', text)\n",
        "    text = re.sub(r'(?:\\n)', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        \"\\U00002702-\\U000027B0\"\n",
        "        \"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE)\n",
        "    text =  emoji_pattern.sub(r'', text)\n",
        "\n",
        "    tokens = tweet_tokenizer.tokenize(text)\n",
        "\n",
        "    return ' '.join([lemma.lemmatize(token.lower().lstrip('#@')) for token in tokens\n",
        "            if token.lower().lstrip('#@') not in stop_words\n",
        "            and token.lower().lstrip('#@').isalpha()\n",
        "            and not token.lower().lstrip('#@').isnumeric()\n",
        "            and len(token) >= min_length\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3IL5vaeIrcY"
      },
      "outputs": [],
      "source": [
        "tweets_df['cleaned_tweets'] = tweets_df['text'].apply(cleaned_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuz1WfUi3Uhs"
      },
      "source": [
        "## Topic Modeling for News Articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki0f4kYN4Bsl"
      },
      "source": [
        "### Functions Used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YQpiXtN39QI"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning for LDA models on news article text\n",
        "num_processors = multiprocessing.cpu_count()\n",
        "workers = num_processors-1\n",
        "\n",
        "\n",
        "def compute_coherence_values(dictionary, corpus, texts, num_topics_range, alpha_range, eta_range):\n",
        "    \"\"\"\n",
        "    This function computes coherence values for different models.\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in num_topics_range:\n",
        "        for alpha in alpha_range:\n",
        "            for eta in eta_range:\n",
        "                model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics,\n",
        "                                     random_state=100, passes=10, alpha=alpha, eta=eta, per_word_topics=True,\n",
        "                                     workers=workers)\n",
        "                model_list.append(model)\n",
        "                coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "                coherence_values.append((num_topics, alpha, eta, coherencemodel.get_coherence()))\n",
        "\n",
        "    return model_list, coherence_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1BNfsfO3dJN"
      },
      "source": [
        "### Create Bigrams and Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzJaLMVXIrcY"
      },
      "outputs": [],
      "source": [
        "# To create bigrams/trigrams for news article text\n",
        "\n",
        "# Tokenize cleaned news text\n",
        "news_df['cleaned_news_text_tokens'] = news_df['cleaned_news_text'].apply(word_tokenize)\n",
        "\n",
        "# Create Bigrams and Trigrams\n",
        "# Train the models\n",
        "news_text_bigram_model = Phrases(news_df['cleaned_news_text_tokens'], min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "news_text_trigram_model = Phrases(news_text_bigram_model[news_df['cleaned_news_text_tokens']], threshold=100)\n",
        "\n",
        "# Apply the trained models to transform the sentences\n",
        "news_df['news_text_bigrams'] = [news_text_bigram_model[doc] for doc in news_df['cleaned_news_text_tokens']]\n",
        "news_df['news_text_trigrams'] = [news_text_trigram_model[news_text_bigram_model[doc]] for doc in news_df['cleaned_news_text_tokens']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGj35cnZIrcY"
      },
      "outputs": [],
      "source": [
        "# Create a Dictionary and Corpus needed for Topic Modeling: every unique term is assigned an index\n",
        "new_text_dictionary = Dictionary(news_df['news_text_trigrams'])\n",
        "\n",
        "# Filter out words that occur in less than 20 documents, or more than 50% of the documents.\n",
        "new_text_dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "\n",
        "# Create the Corpus: Term Document Frequency\n",
        "news_text_corpus = [new_text_dictionary.doc2bow(text) for text in news_df['news_text_trigrams']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuRSj2Ae4osl"
      },
      "source": [
        "### Select Right Number of Topics via Coherence Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMrLsRWGIrcY"
      },
      "outputs": [],
      "source": [
        "num_topics_range = range(4, 11, 1)\n",
        "alpha_range = ['asymmetric']\n",
        "eta_range = ['auto']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9ZaQBoR4PZc"
      },
      "outputs": [],
      "source": [
        "news_text_model_list, news_text_coherence_values = compute_coherence_values(dictionary=new_text_dictionary,\n",
        "                                                                            corpus=news_text_corpus,\n",
        "                                                                            texts=news_df['news_text_trigrams'],\n",
        "                                                                            num_topics_range=num_topics_range,\n",
        "                                                                            alpha_range=alpha_range,\n",
        "                                                                            eta_range=eta_range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PrKaI_LIrcY",
        "outputId": "d6a4bb9e-5264-4758-922e-02fe06f6cbce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num Topics: 4  Alpha: asymmetric  Eta: auto  Coherence: 0.5569369624599487\n",
            "Num Topics: 5  Alpha: asymmetric  Eta: auto  Coherence: 0.4988000907548926\n",
            "Num Topics: 6  Alpha: asymmetric  Eta: auto  Coherence: 0.5587946643233509\n",
            "Num Topics: 7  Alpha: asymmetric  Eta: auto  Coherence: 0.5000552959851742\n",
            "Num Topics: 8  Alpha: asymmetric  Eta: auto  Coherence: 0.5264889936739028\n",
            "Num Topics: 9  Alpha: asymmetric  Eta: auto  Coherence: 0.5344224289942269\n",
            "Num Topics: 10  Alpha: asymmetric  Eta: auto  Coherence: 0.5547021249102447\n"
          ]
        }
      ],
      "source": [
        "# Displaying the coherence scores for each model for news article text\n",
        "for model_scores in news_text_coherence_values:\n",
        "    print(\"Num Topics:\", model_scores[0], \" Alpha:\", model_scores[1], \" Eta:\", model_scores[2], \" Coherence:\", model_scores[3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dw783qYwJ_m"
      },
      "source": [
        "### Visualize Actual Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP9bO60KIrcY"
      },
      "outputs": [],
      "source": [
        "# Choose three models with relatively high coherence scores to visualize actual topics\n",
        "model_topics4 = news_text_model_list[0]\n",
        "model_topics6 = news_text_model_list[2]\n",
        "model_topics10 = news_text_model_list[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DoZq62PIrcZ",
        "outputId": "f59d706f-0984-4189-9a01-a484e82ea7a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.017*\"market\" + 0.011*\"stock\" + 0.005*\"business\" + 0.005*\"price\" + 0.005*\"data\" + 0.005*\"report\" + 0.005*\"global\" + 0.004*\"technology\" + 0.004*\"product\" + 0.003*\"growth\"'),\n",
              " (1,\n",
              "  '0.054*\"video\" + 0.047*\"music\" + 0.044*\"official\" + 0.011*\"oakland\" + 0.006*\"nba\" + 0.006*\"nfl\" + 0.005*\"game\" + 0.005*\"song\" + 0.004*\"georgia\" + 0.004*\"black_history_month\"'),\n",
              " (2,\n",
              "  '0.005*\"game\" + 0.004*\"best\" + 0.004*\"video\" + 0.004*\"say\" + 0.004*\"ago\" + 0.003*\"hour\" + 0.003*\"like\" + 0.003*\"show\" + 0.003*\"make\" + 0.003*\"people\"'),\n",
              " (3,\n",
              "  '0.024*\"open\" + 0.015*\"tab\" + 0.009*\"link\" + 0.008*\"music\" + 0.007*\"say\" + 0.007*\"people\" + 0.007*\"video\" + 0.004*\"show\" + 0.004*\"see\" + 0.004*\"way\"')]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_topics4.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Ob338E5HaH"
      },
      "source": [
        "With 4 topics, topics 3 and 4 contain many common words with little information, like say, ago, like, make, see, way, etc, making it difficult to generate main ideas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-0qyV7cIrcZ",
        "outputId": "17171171-a4e9-48d2-da95-fd55ce547351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.008*\"stock\" + 0.007*\"business\" + 0.006*\"data\" + 0.005*\"technology\" + 0.005*\"market\" + 0.005*\"product\" + 0.005*\"management\" + 0.005*\"rating\" + 0.004*\"price\" + 0.004*\"report\"'),\n",
              " (1,\n",
              "  '0.055*\"video\" + 0.048*\"music\" + 0.045*\"official\" + 0.012*\"oakland\" + 0.006*\"nba\" + 0.006*\"nfl\" + 0.005*\"game\" + 0.005*\"song\" + 0.004*\"georgia\" + 0.004*\"black_history_month\"'),\n",
              " (2,\n",
              "  '0.005*\"ago\" + 0.004*\"say\" + 0.004*\"hour\" + 0.003*\"show\" + 0.003*\"video\" + 0.003*\"people\" + 0.003*\"http\" + 0.003*\"like\" + 0.003*\"state\" + 0.003*\"would\"'),\n",
              " (3,\n",
              "  '0.031*\"open\" + 0.017*\"tab\" + 0.015*\"link\" + 0.012*\"music\" + 0.010*\"people\" + 0.008*\"video\" + 0.006*\"say\" + 0.005*\"show\" + 0.005*\"join\" + 0.005*\"close_dialog_window\"'),\n",
              " (4,\n",
              "  '0.011*\"game\" + 0.010*\"best\" + 0.006*\"video\" + 0.005*\"review\" + 0.005*\"apple\" + 0.005*\"feature\" + 0.005*\"window\" + 0.004*\"use\" + 0.004*\"deal\" + 0.004*\"gaming\"'),\n",
              " (5,\n",
              "  '0.026*\"market\" + 0.013*\"stock\" + 0.006*\"price\" + 0.005*\"global\" + 0.005*\"report\" + 0.004*\"growth\" + 0.004*\"data\" + 0.004*\"say\" + 0.004*\"billion\" + 0.004*\"investor\"')]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_topics6.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPhoPxGU5NgJ"
      },
      "source": [
        "With 6 topics, topic 3 contain words like ago, say, show, http, like, would. Topic 1 and 6 are quite similar with same words like stock, price, report, data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SymADaDtIrcZ",
        "outputId": "c776df6a-e718-4a0e-fdf4-7e71e4a90d15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.008*\"business\" + 0.006*\"technology\" + 0.006*\"data\" + 0.005*\"product\" + 0.005*\"customer\" + 0.004*\"solution\" + 0.004*\"platform\" + 0.004*\"cloud\" + 0.004*\"global\" + 0.004*\"industry\"'),\n",
              " (1,\n",
              "  '0.009*\"show\" + 0.007*\"say\" + 0.007*\"star\" + 0.004*\"reveals\" + 0.004*\"look\" + 0.004*\"advertisement\" + 0.004*\"black\" + 0.004*\"video\" + 0.004*\"best\" + 0.003*\"two\"'),\n",
              " (2,\n",
              "  '0.008*\"ago\" + 0.005*\"hour\" + 0.004*\"state\" + 0.004*\"people\" + 0.003*\"used\" + 0.003*\"say\" + 0.003*\"cookie\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"week\"'),\n",
              " (3,\n",
              "  '0.017*\"open\" + 0.011*\"link\" + 0.009*\"people\" + 0.008*\"music\" + 0.007*\"say\" + 0.007*\"tab\" + 0.007*\"video\" + 0.006*\"ukraine\" + 0.005*\"russia\" + 0.005*\"russian\"'),\n",
              " (4,\n",
              "  '0.013*\"game\" + 0.012*\"best\" + 0.006*\"open\" + 0.006*\"review\" + 0.006*\"apple\" + 0.006*\"video\" + 0.006*\"tab\" + 0.005*\"deal\" + 0.005*\"feature\" + 0.005*\"gaming\"'),\n",
              " (5,\n",
              "  '0.015*\"stock\" + 0.014*\"market\" + 0.007*\"price\" + 0.005*\"investor\" + 0.004*\"say\" + 0.004*\"billion\" + 0.004*\"inflation\" + 0.003*\"india\" + 0.003*\"business\" + 0.003*\"top\"'),\n",
              " (6,\n",
              "  '0.056*\"video\" + 0.049*\"music\" + 0.046*\"official\" + 0.012*\"oakland\" + 0.006*\"nba\" + 0.006*\"nfl\" + 0.005*\"game\" + 0.005*\"song\" + 0.004*\"georgia\" + 0.004*\"black_history_month\"'),\n",
              " (7,\n",
              "  '0.007*\"use\" + 0.006*\"user\" + 0.006*\"file\" + 0.005*\"data\" + 0.005*\"security\" + 0.005*\"project\" + 0.005*\"software\" + 0.004*\"linux\" + 0.004*\"using\" + 0.004*\"need\"'),\n",
              " (8,\n",
              "  '0.030*\"stock\" + 0.018*\"http\" + 0.018*\"rating\" + 0.015*\"price\" + 0.012*\"quarter\" + 0.012*\"holding\" + 0.010*\"nyse\" + 0.008*\"buy\" + 0.008*\"report\" + 0.008*\"position\"'),\n",
              " (9,\n",
              "  '0.053*\"market\" + 0.012*\"global\" + 0.011*\"report\" + 0.008*\"growth\" + 0.008*\"data\" + 0.007*\"forecast\" + 0.007*\"research\" + 0.007*\"analysis\" + 0.006*\"industry\" + 0.005*\"size\"')]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_topics10.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJZ5sFsA5T-E"
      },
      "source": [
        "With 10 topics, even if each topic still contains some useless words like say, http, would, each individual topic has more distinct/unique signal words that distinguish them from other topics and determine the central idea. So I chose 10 topics and would visualize the key words below to further understand each topic and identify similarities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsYeKirvIrcZ"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQn44l0IrcZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Visualize 10 topics from news text\n",
        "# warnings.filterwarnings('ignore')\n",
        "lda_display = gensimvis.prepare(model_topics10, news_text_corpus, new_text_dictionary, sort_topics=False, mds='mmds')\n",
        "pyLDAvis.display(lda_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ECj3M8h-MXj"
      },
      "source": [
        "![Topics for News Articles](news_text_topics.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX0NDJpu53QQ"
      },
      "source": [
        "**Analysis:**\n",
        "\n",
        "**We can see that these 10 topics are quite different in nature with some overlapping just a little bit.**\n",
        "\n",
        "Topic 1 key words: business, technology, data, product, customer, solution, platform, cloud.\n",
        "\n",
        "Topic 2 key words: star, reveals, advertisement, black, video\n",
        "\n",
        "Topic 3 key words: state, people, cookie, week, user, woman\n",
        "\n",
        "Topic 4 key words: link, people, music, video, ukraine, russia, russian, close_dialog_window\n",
        "\n",
        "Topc 5 key words: game, best, open, review, apple, video, tab, feature, mobile, google\n",
        "\n",
        "Topc 6 key words: stock, market, price, investor, billion, inflation, india, business\n",
        "\n",
        "Topc 7 key words: video, music, official, oakland, nba, nfl, game, georgia, black_history_month\n",
        "\n",
        "Topc 8 key words: user, file, data, security, project, software, linux\n",
        "\n",
        "Topc 9 key words: stock, rating, price, quarter, nyse, buy, report, nasdaq\n",
        "\n",
        "Topc 10 key words: market, global, report, growth, data, forecast, research, analysis\n",
        "\n",
        "**After combining these key words, I came up with these 10 topics for news articles:**\n",
        "\n",
        "Topic 1: use technology & data to help business craft solutions for customers on the cloud platform\n",
        "\n",
        "Topic 2: advertisement videos reveal things about black stars\n",
        "\n",
        "Topic 3: people, in particular women, eat cookies during the week in states\n",
        "\n",
        "Topic 4: people close dialog windows on music and video links in ukraine and russia\n",
        "\n",
        "Topic 5: apple and google mobile features have best video game tabs and reviews\n",
        "\n",
        "Topic 6: stock market prices are impacted by inflation in india for business investors, impacting billions of dollars\n",
        "\n",
        "Topic 7: videos and music about official NBA and NFL games in georgia and oakland during black_history_month\n",
        "\n",
        "Topic 8: user projects involving file data security issues using linux software\n",
        "\n",
        "Topic 9: stock price and rating report from NYSE and Nasdaq this quarter\n",
        "\n",
        "Topic 10: global market report uses data and research to do analysis to forecast growth\n",
        "\n",
        "**Even if there are some overlapping words among certain topics, I believe that each topic is specific with minimized duplication. Therefore, the N for news articles is 10.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-tsT3ib6kLN"
      },
      "source": [
        "## Topic Modeling for Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkiNTEYDpZUw"
      },
      "source": [
        "### Create Bigrams/Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ8F10zbIrcZ"
      },
      "outputs": [],
      "source": [
        "# Tokenize cleaned tweets text\n",
        "tweets_df['cleaned_tweets_tokens'] = tweets_df['cleaned_tweets'].apply(word_tokenize)\n",
        "\n",
        "# Create Bigrams and Trigrams\n",
        "# Train the models\n",
        "tweets_bigram_model = Phrases(tweets_df['cleaned_tweets_tokens'], min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "tweets_trigram_model = Phrases(tweets_bigram_model[tweets_df['cleaned_tweets_tokens']], threshold=100)\n",
        "\n",
        "# Apply the trained models to transform the sentences\n",
        "tweets_df['tweets_bigrams'] = [tweets_bigram_model[doc] for doc in tweets_df['cleaned_tweets_tokens']]\n",
        "tweets_df['tweets_trigrams'] = [tweets_trigram_model[tweets_bigram_model[doc]] for doc in tweets_df['cleaned_tweets_tokens']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAoTrmDPIrcZ"
      },
      "outputs": [],
      "source": [
        "# Create a Dictionary and Corpus needed for Topic Modeling: every unique term is assigned an index\n",
        "tweets_dictionary = Dictionary(tweets_df['tweets_trigrams'])\n",
        "\n",
        "# Filter out words that occur in less than 20 documents, or more than 50% of the documents.\n",
        "tweets_dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "\n",
        "# Create the Corpus: Term Document Frequency\n",
        "tweets_corpus = [tweets_dictionary.doc2bow(text) for text in tweets_df['tweets_trigrams']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-3wS_NjptYE"
      },
      "source": [
        "### Select Right Number of Topics via Coherence Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEzJmenRIrcZ"
      },
      "outputs": [],
      "source": [
        "num_topics_range = range(3, 8, 1)\n",
        "alpha_range = ['asymmetric']\n",
        "eta_range = ['auto']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y46yj11fIrcZ"
      },
      "outputs": [],
      "source": [
        "tweets_model_list, tweets_coherence_values = compute_coherence_values(dictionary=tweets_dictionary,\n",
        "                                                                            corpus=tweets_corpus,\n",
        "                                                                            texts=tweets_df['tweets_trigrams'],\n",
        "                                                                            num_topics_range=num_topics_range,\n",
        "                                                                            alpha_range=alpha_range,\n",
        "                                                                            eta_range=eta_range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq2eyhH6IrcZ",
        "outputId": "8cd8f560-94d1-451e-c9f2-e304a494aada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num Topics: 3  Alpha: asymmetric  Eta: auto  Coherence: 0.3512396691237734\n",
            "Num Topics: 4  Alpha: asymmetric  Eta: auto  Coherence: 0.41765729813247005\n",
            "Num Topics: 5  Alpha: asymmetric  Eta: auto  Coherence: 0.47929999655968986\n",
            "Num Topics: 6  Alpha: asymmetric  Eta: auto  Coherence: 0.5079815339248602\n",
            "Num Topics: 7  Alpha: asymmetric  Eta: auto  Coherence: 0.4968297390722774\n"
          ]
        }
      ],
      "source": [
        "# Displaying the coherence scores for each model for tweets text\n",
        "for model_scores in tweets_coherence_values:\n",
        "    print(\"Num Topics:\", model_scores[0], \" Alpha:\", model_scores[1], \" Eta:\", model_scores[2], \" Coherence:\", model_scores[3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI1b0brDwTvC"
      },
      "source": [
        "### Visualize Actual Topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpfGvvBFIrcZ"
      },
      "outputs": [],
      "source": [
        "# Choose 2 models with relatively high coherence scores to visualize actual topics\n",
        "tweets_model_topics6 = tweets_model_list[3]\n",
        "tweets_model_topics7 = tweets_model_list[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fc1ed-ZIrcZ",
        "outputId": "1ce21232-5ca6-417a-bd32-d0c7f528f23a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.020*\"window\" + 0.016*\"new\" + 0.012*\"business\" + 0.012*\"team\" + 0.011*\"azure\" + 0.010*\"use\" + 0.008*\"office\" + 0.008*\"get\" + 0.007*\"tech\" + 0.007*\"people\"'),\n",
              " (1,\n",
              "  '0.039*\"google\" + 0.029*\"apple\" + 0.022*\"amazon\" + 0.015*\"company\" + 0.014*\"word\" + 0.013*\"year\" + 0.011*\"free\" + 0.011*\"job\" + 0.010*\"team\" + 0.009*\"facebook\"'),\n",
              " (2,\n",
              "  '0.311*\"ever\" + 0.015*\"ceo\" + 0.015*\"cloud\" + 0.014*\"msft\" + 0.013*\"stock\" + 0.011*\"dear\" + 0.011*\"never\" + 0.009*\"formatting\" + 0.009*\"azure\" + 0.008*\"data\"'),\n",
              " (3,\n",
              "  '0.041*\"youtube\" + 0.030*\"viu\" + 0.026*\"premium\" + 0.025*\"excel\" + 0.024*\"netflix\" + 0.024*\"premium_account\" + 0.024*\"grammarly\" + 0.022*\"scribd\" + 0.021*\"canva\" + 0.019*\"spotify\"'),\n",
              " (4,\n",
              "  '0.077*\"xbox\" + 0.043*\"game\" + 0.024*\"sony\" + 0.020*\"year\" + 0.019*\"playstation\" + 0.016*\"buy\" + 0.016*\"gaming\" + 0.014*\"metaverse\" + 0.013*\"billion\" + 0.011*\"one\"'),\n",
              " (5,\n",
              "  '0.041*\"game\" + 0.018*\"like\" + 0.017*\"activision_blizzard\" + 0.016*\"deal\" + 0.016*\"make\" + 0.015*\"company\" + 0.014*\"sony\" + 0.011*\"activision\" + 0.011*\"would\" + 0.011*\"buying\"')]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_model_topics6.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CT5q6lZsdMt"
      },
      "source": [
        "If the total number of topics are 6, there are some overlapping between topics. For example, both topic 1 and 3 contain keyword azure. Both topic 5 and 6 contain keyword sony."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESq5cq2pIrcZ",
        "outputId": "b230d189-56a2-45dc-9cf2-810a07ef56e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.023*\"window\" + 0.017*\"new\" + 0.014*\"azure\" + 0.012*\"team\" + 0.010*\"business\" + 0.010*\"use\" + 0.008*\"office\" + 0.008*\"people\" + 0.008*\"cloud\" + 0.007*\"security\"'),\n",
              " (1,\n",
              "  '0.041*\"google\" + 0.032*\"apple\" + 0.024*\"amazon\" + 0.016*\"company\" + 0.014*\"year\" + 0.011*\"one\" + 0.011*\"team\" + 0.010*\"job\" + 0.010*\"word\" + 0.010*\"facebook\"'),\n",
              " (2,\n",
              "  '0.313*\"ever\" + 0.018*\"ceo\" + 0.013*\"breaking\" + 0.012*\"never\" + 0.012*\"cloud\" + 0.010*\"dear\" + 0.010*\"news\" + 0.009*\"buy\" + 0.009*\"msft\" + 0.009*\"report\"'),\n",
              " (3,\n",
              "  '0.042*\"youtube\" + 0.032*\"viu\" + 0.029*\"premium\" + 0.026*\"netflix\" + 0.025*\"premium_account\" + 0.025*\"grammarly\" + 0.023*\"scribd\" + 0.023*\"canva\" + 0.020*\"spotify\" + 0.019*\"canva_pro\"'),\n",
              " (4,\n",
              "  '0.082*\"xbox\" + 0.045*\"game\" + 0.028*\"sony\" + 0.019*\"playstation\" + 0.017*\"year\" + 0.017*\"buy\" + 0.016*\"gaming\" + 0.013*\"metaverse\" + 0.013*\"company\" + 0.012*\"console\"'),\n",
              " (5,\n",
              "  '0.039*\"game\" + 0.020*\"like\" + 0.017*\"activision_blizzard\" + 0.016*\"deal\" + 0.016*\"company\" + 0.014*\"make\" + 0.013*\"activision\" + 0.012*\"would\" + 0.012*\"billion\" + 0.011*\"sony\"'),\n",
              " (6,\n",
              "  '0.052*\"excel\" + 0.034*\"free\" + 0.026*\"word\" + 0.020*\"data\" + 0.018*\"business\" + 0.015*\"get\" + 0.014*\"power\" + 0.014*\"course\" + 0.013*\"startup\" + 0.012*\"know\"')]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_model_topics7.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ7F9Vnos-a4"
      },
      "source": [
        "Similar to 6 topic model, these 7 topics also have some overlapping in between. For example, both topic 5 and 6 contain keyword sony. But since the 7th topic is a brand new topic without much duplication from previous 6 topics. So I chose 7 topics and would visualize the key words below to further understand each topic and identify similarities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9omdgH9IrcZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Visualize 7 topics from tweets\n",
        "# warnings.filterwarnings('ignore')\n",
        "lda_display = gensimvis.prepare(tweets_model_topics7, tweets_corpus, tweets_dictionary, sort_topics=False, mds='mmds')\n",
        "pyLDAvis.display(lda_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O41u1orf-MXk"
      },
      "source": [
        "![Topics for News Articles](tweets_topics.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_xiXi3ztK4M"
      },
      "source": [
        "**Analysis:**\n",
        "\n",
        "**We can see that all 7 topics are far apart from each other without any overlapping.**\n",
        "\n",
        "Topic 1 key words: azure, team, business, use, office, cloud, security\n",
        "\n",
        "Topic 2 key words: google, apple, amazon, company, year, team, job, facebook, meta\n",
        "\n",
        "Topic 3 key words: ceo, breaking, cloud, news, msft, report, stock\n",
        "\n",
        "Topic 4 key words: youtube, premium, netflix, premium_account, grammarly, scribd, canva, spotify\n",
        "\n",
        "Topic 5 key words: xbox, game, sony, playstation, gaming, metaverse, company\n",
        "\n",
        "Topic 6 key words: game, activision_blizzard, deal, company, billion, sony\n",
        "\n",
        "Topic 7 key words: excel, free, data, business, power, startup, training, technology\n",
        "\n",
        "**After combining these key words, I came up with these 7 topics for tweets:**\n",
        "\n",
        "Topic 1: azure cloud service is for teams and businesses to use in office for data security\n",
        "\n",
        "Topic 2: teams and jobs in huge companies like google, apply, amazon, facebook, and meta this year\n",
        "\n",
        "Topic 3: breaking news about msft cloud services, ceo, and stock report\n",
        "\n",
        "Topic 4: premium accounts for popular social/entertainment platforms like youtube, netflix, scribd, canva, spotify\n",
        "\n",
        "Topic 5: games from playstation of sony, xbox, and metaverse game companies\n",
        "\n",
        "Topic 6: game company activision_blizzard has a billion deal with sony\n",
        "\n",
        "Topic 7: startup businesses excel at powering free data training and technology\n",
        "\n",
        "Topic 5 & 6 are extremely similar and are both about video games, and game companies, so can be merged into one topic.\n",
        "\n",
        "Other than this, the rest 5 topics are specific with minimized duplication.\n",
        "\n",
        "**Therefore, the N for tweets is 6.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}